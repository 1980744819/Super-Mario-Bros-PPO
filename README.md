# Super Mario Bros with PPO

In this repo, we use Proximal Policy Optimization (PPO) to allow our agent to learn how to play Super Mario Bros from raw pixels. 

The hyperparameters that you'll find in the source file are not the optimal hyperparameters, so please play around with them and see if you can find the best ones!
